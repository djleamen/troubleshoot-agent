{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0833eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            timestamp  cpu_usage  memory_usage  network_latency    disk_io  \\\n",
      "0 2024-01-01 00:00:00  53.047171     59.110760        90.960980  87.490227   \n",
      "1 2024-01-01 01:00:00  39.600159     49.060696        86.682446  81.876922   \n",
      "2 2024-01-01 02:00:00  57.504512     53.782904       108.680196  94.661275   \n",
      "3 2024-01-01 03:00:00  59.405647     69.508656       105.037088  59.521672   \n",
      "4 2024-01-01 04:00:00  30.489648     60.044899        71.904169  72.346399   \n",
      "\n",
      "   error_rate  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# Generate synthetic data\n",
    "n_samples = 1000\n",
    "data = {\n",
    "    'timestamp': pd.date_range(start='2024-01-01', periods=n_samples, freq='h'),\n",
    "    'cpu_usage': rng.normal(50, 10, n_samples),       # CPU usage in percentage\n",
    "    'memory_usage': rng.normal(60, 15, n_samples),    # Memory usage in percentage\n",
    "    'network_latency': rng.normal(100, 20, n_samples), # Network latency in ms\n",
    "    'disk_io': rng.normal(75, 10, n_samples),         # Disk I/O in MB/s\n",
    "    'error_rate': rng.choice([0, 1], n_samples, p=[0.95, 0.05])  # 5% error rate\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f01cd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomaly\n",
      " 1    950\n",
      "-1     50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Implement anomaly detection using Isolation Forest\n",
    "def detect_anomalies(data):\n",
    "    model = IsolationForest(contamination=0.05, random_state=42)\n",
    "    model.fit(data)\n",
    "    anomalies = model.predict(data)\n",
    "    return anomalies\n",
    "\n",
    "# Detect anomalies in the dataset \n",
    "numeric_data = df.select_dtypes(include=[float, int]) # Only numeric columns \n",
    "df['anomaly'] = detect_anomalies(numeric_data)\n",
    "\n",
    "print(df['anomaly'].value_counts()) # -1 denotes an anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfaa1b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              timestamp  anomaly anomalous_columns\n",
      "26  2024-01-02 02:00:00       -1      [error_rate]\n",
      "30  2024-01-02 06:00:00       -1      [error_rate]\n",
      "53  2024-01-03 05:00:00       -1                []\n",
      "76  2024-01-04 04:00:00       -1      [error_rate]\n",
      "78  2024-01-04 06:00:00       -1      [error_rate]\n",
      "83  2024-01-04 11:00:00       -1      [error_rate]\n",
      "124 2024-01-06 04:00:00       -1      [error_rate]\n",
      "136 2024-01-06 16:00:00       -1      [error_rate]\n",
      "141 2024-01-06 21:00:00       -1         [disk_io]\n",
      "142 2024-01-06 22:00:00       -1                []\n",
      "164 2024-01-07 20:00:00       -1      [error_rate]\n",
      "166 2024-01-07 22:00:00       -1      [error_rate]\n",
      "176 2024-01-08 08:00:00       -1      [error_rate]\n",
      "194 2024-01-09 02:00:00       -1      [error_rate]\n",
      "208 2024-01-09 16:00:00       -1      [error_rate]\n",
      "262 2024-01-11 22:00:00       -1      [error_rate]\n",
      "269 2024-01-12 05:00:00       -1      [error_rate]\n",
      "277 2024-01-12 13:00:00       -1                []\n",
      "357 2024-01-15 21:00:00       -1      [error_rate]\n",
      "369 2024-01-16 09:00:00       -1      [error_rate]\n",
      "374 2024-01-16 14:00:00       -1      [error_rate]\n",
      "385 2024-01-17 01:00:00       -1      [error_rate]\n",
      "398 2024-01-17 14:00:00       -1      [error_rate]\n",
      "411 2024-01-18 03:00:00       -1                []\n",
      "448 2024-01-19 16:00:00       -1      [error_rate]\n",
      "452 2024-01-19 20:00:00       -1      [error_rate]\n",
      "466 2024-01-20 10:00:00       -1      [error_rate]\n",
      "476 2024-01-20 20:00:00       -1                []\n",
      "489 2024-01-21 09:00:00       -1      [error_rate]\n",
      "501 2024-01-21 21:00:00       -1      [error_rate]\n",
      "508 2024-01-22 04:00:00       -1      [error_rate]\n",
      "515 2024-01-22 11:00:00       -1      [error_rate]\n",
      "551 2024-01-23 23:00:00       -1      [error_rate]\n",
      "590 2024-01-25 14:00:00       -1      [error_rate]\n",
      "606 2024-01-26 06:00:00       -1      [error_rate]\n",
      "663 2024-01-28 15:00:00       -1      [error_rate]\n",
      "687 2024-01-29 15:00:00       -1      [error_rate]\n",
      "690 2024-01-29 18:00:00       -1      [error_rate]\n",
      "699 2024-01-30 03:00:00       -1      [error_rate]\n",
      "795 2024-02-03 03:00:00       -1      [error_rate]\n",
      "829 2024-02-04 13:00:00       -1                []\n",
      "849 2024-02-05 09:00:00       -1      [error_rate]\n",
      "859 2024-02-05 19:00:00       -1      [error_rate]\n",
      "913 2024-02-08 01:00:00       -1                []\n",
      "915 2024-02-08 03:00:00       -1                []\n",
      "947 2024-02-09 11:00:00       -1                []\n",
      "949 2024-02-09 13:00:00       -1       [cpu_usage]\n",
      "951 2024-02-09 15:00:00       -1      [error_rate]\n",
      "955 2024-02-09 19:00:00       -1      [error_rate]\n",
      "980 2024-02-10 20:00:00       -1      [error_rate]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "# Calculate z-scores to identify anomalous values per column in anomalous rows\n",
    "z_scores = numeric_data.apply(zscore)\n",
    "\n",
    "# Function to identify anomalous columns for each row\n",
    "def find_anomalous_columns(row, threshold=3):\n",
    "    return [col for col in numeric_data.columns if abs(z_scores.loc[row.name, col]) > threshold]\n",
    "\n",
    "# Apply the function to each anomalous row\n",
    "df['anomalous_columns'] = df.apply(lambda row: find_anomalous_columns(row) if row['anomaly'] == -1 else [], axis=1)\n",
    "\n",
    "# Display rows with anomalies and their anomalous columns\n",
    "print(df[df['anomaly'] == -1][['timestamp', 'anomaly', 'anomalous_columns']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3111e9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted causes shape: (1000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Train a decision tree for root cause analysis\n",
    "def root_cause_analysis(X_train, y_train, X_test):\n",
    "    model = DecisionTreeClassifier(ccp_alpha=0.0, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    return predictions\n",
    "\n",
    "# Prepare data for root cause analysis (only numeric columns)\n",
    "X_train = df.drop(['anomaly', 'timestamp', 'anomalous_columns'], axis=1, errors='ignore')\n",
    "y_train = df['anomaly']\n",
    "predicted_causes = root_cause_analysis(X_train, y_train, X_train)\n",
    "print(f\"Predicted causes shape: {predicted_causes.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "101a9b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended solution: Restart the network service.\n"
     ]
    }
   ],
   "source": [
    "# Example solution recommendation based on root cause\n",
    "def recommend_solution(root_cause):\n",
    "    solutions = {\n",
    "        \"network_error\": \"Restart the network service.\",\n",
    "        \"database_issue\": \"Check the database connection and restart the service.\",\n",
    "        \"high_cpu_usage\": \"Optimize running processes or allocate more resources.\"\n",
    "    }\n",
    "    return solutions.get(root_cause, \"No recommendation available.\")\n",
    "\n",
    "# Recommend a solution based on a detected root cause\n",
    "solution = recommend_solution(\"network_error\")\n",
    "print(f\"Recommended solution: {solution}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb2ffea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected issue: 1\n",
      "Recommended solution: No recommendation available.\n"
     ]
    }
   ],
   "source": [
    "# Simulate a network error by altering the dataset\n",
    "df.loc[0, 'network_latency'] = 1000  # Simulating high network latency\n",
    "\n",
    "# Prepare numeric data for prediction\n",
    "numeric_test_data = df.drop(['anomaly', 'timestamp', 'anomalous_columns'], axis=1, errors='ignore')\n",
    "\n",
    "# Run the troubleshooting agent\n",
    "anomalies = detect_anomalies(df.select_dtypes(include=[float, int]))\n",
    "predicted_causes = root_cause_analysis(X_train, y_train, numeric_test_data)\n",
    "solution = recommend_solution(predicted_causes[0])\n",
    "print(f\"Detected issue: {predicted_causes[0]}\")\n",
    "print(f\"Recommended solution: {solution}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

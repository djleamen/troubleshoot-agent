{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0833eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic data\n",
    "n_samples = 1000\n",
    "data = {\n",
    "    'timestamp': pd.date_range(start='2024-01-01', periods=n_samples, freq='h'),\n",
    "    'cpu_usage': np.random.normal(50, 10, n_samples),       # CPU usage in percentage\n",
    "    'memory_usage': np.random.normal(60, 15, n_samples),    # Memory usage in percentage\n",
    "    'network_latency': np.random.normal(100, 20, n_samples), # Network latency in ms\n",
    "    'disk_io': np.random.normal(75, 10, n_samples),         # Disk I/O in MB/s\n",
    "    'error_rate': np.random.choice([0, 1], n_samples, p=[0.95, 0.05])  # 5% error rate\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f01cd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Implement anomaly detection using Isolation Forest\n",
    "def detect_anomalies(data):\n",
    "    model = IsolationForest(contamination=0.05, random_state=42)\n",
    "    model.fit(data)\n",
    "    anomalies = model.predict(data)\n",
    "    return anomalies\n",
    "\n",
    "# Detect anomalies in the dataset \n",
    "numeric_data = df.select_dtypes(include=[float, int]) # Only numeric columns \n",
    "df['anomaly'] = detect_anomalies(numeric_data)\n",
    "\n",
    "print(df['anomaly'].value_counts()) # -1 denotes an anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaa1b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "# Calculate z-scores to identify anomalous values per column in anomalous rows\n",
    "z_scores = numeric_data.apply(zscore)\n",
    "\n",
    "# Function to identify anomalous columns for each row\n",
    "def find_anomalous_columns(row, threshold=3):\n",
    "    return [col for col in numeric_data.columns if abs(z_scores.loc[row.name, col]) > threshold]\n",
    "\n",
    "# Apply the function to each anomalous row\n",
    "df['anomalous_columns'] = df.apply(lambda row: find_anomalous_columns(row) if row['anomaly'] == -1 else [], axis=1)\n",
    "\n",
    "# Display rows with anomalies and their anomalous columns\n",
    "print(df[df['anomaly'] == -1][['timestamp', 'anomaly', 'anomalous_columns']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3111e9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Train a decision tree for root cause analysis\n",
    "def root_cause_analysis(X_train, y_train, X_test):\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    return predictions\n",
    "\n",
    "# Prepare data for root cause analysis (only numeric columns)\n",
    "X_train = df.drop(['anomaly', 'timestamp', 'anomalous_columns'], axis=1, errors='ignore')\n",
    "y_train = df['anomaly']\n",
    "predicted_causes = root_cause_analysis(X_train, y_train, X_train)\n",
    "print(f\"Predicted causes shape: {predicted_causes.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101a9b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example solution recommendation based on root cause\n",
    "def recommend_solution(root_cause):\n",
    "    solutions = {\n",
    "        \"network_error\": \"Restart the network service.\",\n",
    "        \"database_issue\": \"Check the database connection and restart the service.\",\n",
    "        \"high_cpu_usage\": \"Optimize running processes or allocate more resources.\"\n",
    "    }\n",
    "    return solutions.get(root_cause, \"No recommendation available.\")\n",
    "\n",
    "# Recommend a solution based on a detected root cause\n",
    "solution = recommend_solution(\"network_error\")\n",
    "print(f\"Recommended solution: {solution}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2ffea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a network error by altering the dataset\n",
    "df.loc[0, 'network_latency'] = 1000  # Simulating high network latency\n",
    "\n",
    "# Prepare numeric data for prediction\n",
    "numeric_test_data = df.drop(['anomaly', 'timestamp', 'anomalous_columns'], axis=1, errors='ignore')\n",
    "\n",
    "# Run the troubleshooting agent\n",
    "anomalies = detect_anomalies(df.select_dtypes(include=[float, int]))\n",
    "predicted_causes = root_cause_analysis(X_train, y_train, numeric_test_data)\n",
    "solution = recommend_solution(predicted_causes[0])\n",
    "print(f\"Detected issue: {predicted_causes[0]}\")\n",
    "print(f\"Recommended solution: {solution}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

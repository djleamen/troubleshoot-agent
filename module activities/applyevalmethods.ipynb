{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "640a5748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Actual labels and predicted labels from your model\n",
    "y_true = [1, 0, 1, 1, 0, 1]\n",
    "y_pred = [1, 0, 1, 0, 0, 1]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb45c9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_true, y_pred)\n",
    "print(f\"Precision: {precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "879451ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_true, y_pred)\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20dd27fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ae83980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0]\n",
      " [1 3]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Generate confusion matrix\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ce58d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Calculate ROC-AUC score\n",
    "roc_auc = roc_auc_score(y_true, y_pred)\n",
    "print(f\"ROC-AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "652a4036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2573375105857849\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the cross-entropy loss function\n",
    "# CrossEntropyLoss is used for classification tasks where the model outputs class probabilities.\n",
    "# It combines LogSoftmax and Negative Log Likelihood Loss into one function, making it efficient for such tasks.\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Example prediction and actual class (as tensors)\n",
    "# Here, we create a tensor called 'output' representing the predicted scores (unnormalized) for two data points.\n",
    "# Each row corresponds to a data point, and the values represent the scores for each class.\n",
    "# Note that CrossEntropyLoss internally applies the softmax function to these scores to obtain probabilities.\n",
    "output = torch.tensor([[0.5, 1.5], [2.0, 0.5]])\n",
    "\n",
    "# 'target' is a tensor representing the actual classes for the two data points.\n",
    "# In this example, the first data point belongs to class 1, and the second data point belongs to class 0.\n",
    "# These class indices are zero-based, meaning 0 represents the first class, 1 represents the second, and so on.\n",
    "target = torch.tensor([1, 0])\n",
    "\n",
    "# Calculate loss\n",
    "# The CrossEntropyLoss function will take the predicted scores ('output') and the actual labels ('target')\n",
    "# to compute the loss value, which quantifies how well the model's predictions match the actual labels.\n",
    "# Lower loss values indicate better predictions, while higher values indicate more errors.\n",
    "loss = loss_fn(output, target)\n",
    "\n",
    "# Print the computed loss value\n",
    "# '.item()' is used to get the Python scalar value from the tensor containing the loss.\n",
    "print(f\"Loss: {loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
